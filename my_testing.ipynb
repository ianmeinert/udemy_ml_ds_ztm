{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastparquet as fpq\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import polars as pl\n",
    "import sys\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = .7\n",
    "VALIDATION_SIZE = .15\n",
    "MBTA_PATH = Path(\"MBTA\")\n",
    "\n",
    "# data retrieved from https://mbta-massdot.opendata.arcgis.com/datasets/MassDOT::mbta-bus-arrival-departure-times-2022/about\n",
    "MBTA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MBTA_CSV = MBTA_PATH / \"MBTA-Bus-Arrival-Departure-Times_2022-05.csv\"\n",
    "MBTA_PARQUET = MBTA_PATH / \"MBTA-Bus-Arrival-Departure-Times_2022-05.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
      "[71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
      "[86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "# Build sample data\n",
    "data_set = list(range(1,100))\n",
    "data_size = len(data_set)\n",
    "# Training data set\n",
    "# - Use this set for model training\n",
    "# - 70–80% of your data is the standard\n",
    "trng_limit = math.ceil(data_size*TRAINING_SIZE)\n",
    "training_data = data_set[:trng_limit]\n",
    "\n",
    "# Validation/development data set\n",
    "# - Use this set for model hyperparameter tuning and experimentation evaluation\n",
    "# - 10–15% of your data is the standard\n",
    "val_size = math.ceil(data_size*VALIDATION_SIZE)\n",
    "val_limit = trng_limit+val_size\n",
    "validation_data = data_set[trng_limit:val_limit]\n",
    "\n",
    "# Test data set\n",
    "# - Use this set for model testing and comparison\n",
    "# - 10–15% of your data is the standard.\n",
    "# - Training and test data should be separated.\n",
    "# - Test data shouldnt be used for model improvement\n",
    "test_data = data_set[val_limit:]\n",
    "\n",
    "print(data_set)\n",
    "print(training_data)\n",
    "print(validation_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_model():\n",
    "    data = []\n",
    "    training_data = []\n",
    "    validation_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    _TRAINING_SIZE = 0\n",
    "    _VALIDATION_SIZE = 0    \n",
    "    \n",
    "    def __init__(self, training_size=.70, validation_size=.15):\n",
    "        self._TRAINING_SIZE = training_size\n",
    "        self._VALIDATION_SIZE = validation_size\n",
    "    \n",
    "    \n",
    "    def build_models(self, data):\n",
    "        self.data = data\n",
    "        data_size = len(self.data)\n",
    "        \n",
    "        trng_limit = math.ceil(data_size*self._TRAINING_SIZE)\n",
    "        self.training_data = data[:trng_limit]\n",
    "        \n",
    "        val_size = math.ceil(data_size*self._VALIDATION_SIZE)\n",
    "        val_limit = trng_limit+val_size        \n",
    "        self.validation_data = data[trng_limit:val_limit]\n",
    "        \n",
    "        self.test_data = data[val_limit:]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
      "[81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "[91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "datamodel = data_model(.8,.1)\n",
    "datamodel.build_models(data_set)\n",
    "\n",
    "print(datamodel.training_data)\n",
    "print(datamodel.validation_data)\n",
    "print(datamodel.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Polars\n",
    "### Ref: https://pythonspeed.com/articles/polars-memory-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service_date         datetime64[ns]\n",
       "route_id                     string\n",
       "direction_id                 object\n",
       "half_trip_id                float64\n",
       "stop_id                       int64\n",
       "time_point_id                object\n",
       "time_point_order              int64\n",
       "point_type                   object\n",
       "standard_type                object\n",
       "scheduled            datetime64[ns]\n",
       "actual               datetime64[ns]\n",
       "scheduled_headway           float64\n",
       "headway                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(MBTA_CSV,\n",
    "                dtype={\"route_id\":\"string\",},\n",
    "                parse_dates=[\"service_date\",\"scheduled\",\"actual\"],)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_col in [\"route_id\",\"direction_id\",\"point_type\",\"standard_type\"]:\n",
    "    df[categorical_col] = df[categorical_col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(str(MBTA_CSV).replace(\".csv\",\".parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Naive Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_headways_pandas():\n",
    "    # Load the data\n",
    "    data = pd.read_parquet(MBTA_PARQUET)\n",
    "    # Filter down to headway points only\n",
    "    data[data[\"standard_type\"] == \"headway\"]\n",
    "    # Calc ratio of actual headway to expected headway\n",
    "    data[\"headway_ratio\"] = data.headway / data.scheduled_headway\n",
    "    # Group by route and direction (inbound/outbound)\n",
    "    by_route = data.groupby([\"route_id\",\"direction_id\"])\n",
    "    # Find median headway ratio for each route\n",
    "    median_headway = by_route[[\"headway_ratio\"]].median()\n",
    "    # Return the worst 5 routes:\n",
    "    return median_headway.nlargest(5, columns=[\"headway_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1558.98 MiB, increment: 653.30 MiB\n",
      "peak memory: 1519.84 MiB, increment: 197.69 MiB\n",
      "peak memory: 1423.19 MiB, increment: 380.68 MiB\n",
      "peak memory: 1552.89 MiB, increment: 422.68 MiB\n",
      "peak memory: 1538.85 MiB, increment: 331.45 MiB\n",
      "peak memory: 1537.22 MiB, increment: 586.12 MiB\n",
      "peak memory: 1456.21 MiB, increment: 100.11 MiB\n",
      "peak memory: 1518.45 MiB, increment: 532.35 MiB\n",
      "874 ms ± 80.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%%memit\n",
    "find_worst_headways_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More Optimized Pandas Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_headways_pandas_opt():\n",
    "    # Load the data in chunks\n",
    "    chunks = []\n",
    "    parquet_file = pq.ParquetFile(MBTA_PARQUET)\n",
    "    \n",
    "    for batch in parquet_file.iter_batches():\n",
    "        chunk = batch.to_pandas()\n",
    "        del batch\n",
    "        # Calculate headway ratio:\n",
    "        chunk[\"headway_ratio\"] = chunk.headway / chunk.scheduled_headway\n",
    "        # Store the columns we care about for this chunk\n",
    "        chunks.append(chunk[[\"route_id\",\"direction_id\",\"headway_ratio\"]])\n",
    "    \n",
    "    del parquet_file\n",
    "    \n",
    "    # Concatenate into one big DataFrame\n",
    "    # Not ideal, involves two copies in memory at once\n",
    "    data = pd.concat(chunks)\n",
    "    del chunks\n",
    "    \n",
    "    # Group by route and direction (inbound/outbound)\n",
    "    by_route = data.groupby([\"route_id\",\"direction_id\"])\n",
    "    # Find median day's headway ratio for each route\n",
    "    median_headway = by_route[[\"headway_ratio\"]].median()\n",
    "    # Return the worst 5 routes\n",
    "    return median_headway.nlargest(5, columns=[\"headway_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1321.98 MiB, increment: 0.00 MiB\n",
      "peak memory: 915.65 MiB, increment: 49.63 MiB\n",
      "peak memory: 1026.07 MiB, increment: 151.88 MiB\n",
      "peak memory: 1023.53 MiB, increment: 128.78 MiB\n",
      "peak memory: 1011.85 MiB, increment: 141.62 MiB\n",
      "peak memory: 1027.65 MiB, increment: 164.15 MiB\n",
      "peak memory: 1019.18 MiB, increment: 130.56 MiB\n",
      "peak memory: 1024.36 MiB, increment: 150.79 MiB\n",
      "964 ms ± 8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%%memit\n",
    "find_worst_headways_pandas_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_headways_pandas_fast():\n",
    "    # Load the data\n",
    "    data = pd.read_parquet(MBTA_PARQUET, engine=\"fastparquet\")\n",
    "    # Filter down to headway points only\n",
    "    data[data[\"standard_type\"] == \"headway\"]\n",
    "    # Calc ratio of actual headway to expected headway\n",
    "    data[\"headway_ratio\"] = data.headway / data.scheduled_headway\n",
    "    # Group by route and direction (inbound/outbound)\n",
    "    by_route = data.groupby([\"route_id\",\"direction_id\"])\n",
    "    # Find median headway ratio for each route\n",
    "    median_headway = by_route[[\"headway_ratio\"]].median()\n",
    "    # Return the worst 5 routes:\n",
    "    return median_headway.nlargest(5, columns=[\"headway_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_headways_pandas_opt_fast():\n",
    "    # Load the data in chunks\n",
    "    chunks = []\n",
    "    parquet_file = fpq.ParquetFile(MBTA_PARQUET)\n",
    "    \n",
    "    for chunk in parquet_file.iter_row_groups():    \n",
    "        # Calculate headway ratio:\n",
    "        chunk[\"headway_ratio\"] = chunk.headway / chunk.scheduled_headway\n",
    "        # Store the columns we care about for this chunk\n",
    "        chunks.append(chunk[[\"route_id\",\"direction_id\",\"headway_ratio\"]])\n",
    "    \n",
    "    del parquet_file\n",
    "    \n",
    "    # Concatenate into one big DataFrame\n",
    "    # Not ideal, involves two copies in memory at once\n",
    "    data = pd.concat(chunks)\n",
    "    del chunks\n",
    "    \n",
    "    # Group by route and direction (inbound/outbound)\n",
    "    by_route = data.groupby([\"route_id\",\"direction_id\"])\n",
    "    # Find median day's headway ratio for each route\n",
    "    median_headway = by_route[[\"headway_ratio\"]].median()\n",
    "    # Return the worst 5 routes\n",
    "    return median_headway.nlargest(5, columns=[\"headway_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1109.43 MiB, increment: 240.99 MiB\n",
      "peak memory: 1080.45 MiB, increment: 271.53 MiB\n",
      "peak memory: 1080.45 MiB, increment: 271.76 MiB\n",
      "peak memory: 1080.20 MiB, increment: 271.51 MiB\n",
      "peak memory: 1080.45 MiB, increment: 271.77 MiB\n",
      "peak memory: 1080.46 MiB, increment: 271.77 MiB\n",
      "peak memory: 1071.96 MiB, increment: 263.28 MiB\n",
      "peak memory: 1075.96 MiB, increment: 267.28 MiB\n",
      "1.54 s ± 8.97 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%%memit\n",
    "find_worst_headways_pandas_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1008.09 MiB, increment: 199.40 MiB\n",
      "peak memory: 1050.04 MiB, increment: 241.35 MiB\n",
      "peak memory: 1042.04 MiB, increment: 233.36 MiB\n",
      "peak memory: 1010.26 MiB, increment: 201.57 MiB\n",
      "peak memory: 1010.26 MiB, increment: 201.57 MiB\n",
      "peak memory: 1020.00 MiB, increment: 211.31 MiB\n",
      "peak memory: 1072.07 MiB, increment: 263.39 MiB\n",
      "peak memory: 1062.04 MiB, increment: 253.35 MiB\n",
      "1.55 s ± 9.53 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%%memit\n",
    "find_worst_headways_pandas_opt_fast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polars Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headways_sorted_worst_first():\n",
    "    # Load the data lazily\n",
    "    data = pl.scan_parquet(MBTA_PARQUET)\n",
    "    # Filter down to headway points only and then select\n",
    "    # the data we need\n",
    "    data = data.filter(pl.col(\"standard_type\") == \"Headway\"\n",
    "                      ).select([\n",
    "                            pl.col(\"route_id\"),\n",
    "                            pl.col(\"direction_id\"),\n",
    "                            pl.col(\"headway\") / pl.col(\"scheduled_headway\"),\n",
    "                        ])\n",
    "    \n",
    "    # Group by route and direction (inbound/outbound)\n",
    "    by_route = data.groupby([\"route_id\",\"direction_id\"])\n",
    "    # Find the median headway ratio for each route\n",
    "    median_headway = by_route.agg(pl.col(\"headway\").median())\n",
    "    # Theres no nlargest() method, so instead just sort in descending order\n",
    "    return median_headway.sort(\"headway\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 943.31 MiB, increment: 12.02 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 957.12 MiB, increment: 13.80 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 947.12 MiB, increment: 0.00 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 948.35 MiB, increment: 1.31 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 948.58 MiB, increment: 0.23 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 957.63 MiB, increment: 9.05 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 960.77 MiB, increment: 16.57 MiB\n",
      "shape: (5, 3)\n",
      "┌──────────┬──────────────┬──────────┐\n",
      "│ route_id ┆ direction_id ┆ headway  │\n",
      "│ ---      ┆ ---          ┆ ---      │\n",
      "│ cat      ┆ cat          ┆ f64      │\n",
      "╞══════════╪══════════════╪══════════╡\n",
      "│ 108      ┆ Outbound     ┆ 2.9      │\n",
      "│ 88       ┆ Outbound     ┆ 1.68     │\n",
      "│ 83       ┆ Outbound     ┆ 1.565    │\n",
      "│ 134      ┆ Outbound     ┆ 1.431111 │\n",
      "│ 134      ┆ Inbound      ┆ 1.346667 │\n",
      "└──────────┴──────────────┴──────────┘\n",
      "peak memory: 960.91 MiB, increment: 0.14 MiB\n",
      "555 ms ± 21.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%%memit\n",
    "# Create the query\n",
    "query = headways_sorted_worst_first()\n",
    "# Actually run the query\n",
    "result = query.collect()\n",
    "# Print the 5 worst headways:\n",
    "print(result[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "61bab3e243e08f6c7503b90abd0999dfa4d5ec84e62a08ef3c26955cfa7fb0e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
